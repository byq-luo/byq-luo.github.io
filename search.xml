<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>内嵌视频测试！</title>
      <link href="/2019/09/06/sp/"/>
      <url>/2019/09/06/sp/</url>
      
        <content type="html"><![CDATA[<h1 id="视频测试"><a href="#视频测试" class="headerlink" title="视频测试"></a>视频测试</h1><div id="dplayer0" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer0"),"theme":"#FADFA3","loop":true,"video":{"url":"https://github.com/kraten/vehicle-speed-check/cars.mp4","pic":"http://yanghexo.cn-bj.ufileos.com/github.jpg"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> github </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pandas </tag>
            
            <tag> Python </tag>
            
            <tag> Matplotlib </tag>
            
            <tag> Seaborn </tag>
            
            <tag> Plotly </tag>
            
            <tag> Pyecharts </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>充气娃娃什么感觉？Python告诉你</title>
      <link href="/2019/09/04/chong-qi-wa-wa-shi-me-gan-jue-python-gao-su-ni/"/>
      <url>/2019/09/04/chong-qi-wa-wa-shi-me-gan-jue-python-gao-su-ni/</url>
      
        <content type="html"><![CDATA[<h1 id="充气娃娃什么感觉？Python告诉你"><a href="#充气娃娃什么感觉？Python告诉你" class="headerlink" title="充气娃娃什么感觉？Python告诉你"></a>充气娃娃什么感觉？Python告诉你</h1><p>今天就带大家来玩一把刺激的！</p><h2 id="一、需求背景"><a href="#一、需求背景" class="headerlink" title="一、需求背景"></a>一、需求背景</h2><p>在实际开发过程中，在我们动手开发之前，都是由产品经理为我们（测试、前端、后端、项目经理等）先讲解一下需求，我们了解了需求之后，才开始一起来讨论技术方案。<br><img src="/images/pasted-0.png" alt="upload successful"></p><p>我们自己实现一些小功能时同样需要讨论需求，也就是告诉别人我们为什么要做这个东西？或者我们想利用这款产品解决什么问题。</p><p>我们常常看到一些有关充气娃娃的表情包和图片或新闻，但是这种东西很少会像一些小视频一些相互交流，大家可能都是偷摸玩耍。所以猪哥相信其实大部分同学并没有亲身体验过充气娃娃到底是什么感觉（包括猪哥），所以猪哥很好奇究竟是什么一种体验？真的如传言中那样爽吗？</p><p><img src="/images/pasted-1.png" alt="upload successful"></p><h2 id="二、功能描述"><a href="#二、功能描述" class="headerlink" title="二、功能描述"></a>二、功能描述</h2><p>基于很多人没有体验过充气娃娃是什么感觉，但是又很好奇，所以希望通过爬虫+数据分析的方式直观而真实的告诉大家（下图为成品图）。</p><p><img src="/images/pasted-2.png" alt="upload successful"></p><h2 id="三、技术方案"><a href="#三、技术方案" class="headerlink" title="三、技术方案"></a>三、技术方案</h2><p>为了实现上面的需求以及功能，我们来讨论下具体的技术实现方案：</p><p>分析某东评论数据请求</p><p>使用requests库抓取某东的充气娃娃评论</p><p>使用词云做数据展示</p><h2 id="四、技术实现"><a href="#四、技术实现" class="headerlink" title="四、技术实现"></a>四、技术实现</h2><p>上篇文章中就给大家说过，今天我们以某东商品编号为：1263013576的商品为对象，进行数据分析，我们来看看详细的技术实现步骤吧！</p><p>本教程只为学习交流，不得用于商用获利，后果自负！<br>如有侵权或者对任何公司或个人造成不利影响，请告知删除</p><h3 id="1-分析并获取评论接口的URL"><a href="#1-分析并获取评论接口的URL" class="headerlink" title="1.分析并获取评论接口的URL"></a>1.分析并获取评论接口的URL</h3><p>第一步：打开某东的商品页，搜索你想研究的商品。</p><p><img src="/images/pasted-3.png" alt="upload successful"></p><p>第二步：我们在页面中鼠标右键选择检查（或F12）调出浏览器的调试窗口。</p><p><img src="/images/pasted-4.png" alt="upload successful"></p><p>第三步：调出浏览器后点击评论按钮使其加载数据，然后我们点击network查看数据。</p><p><img src="/images/pasted-5.png" alt="upload successful"></p><p>第四步：查找加载评论数据的请求url，我们可以使用某条评论中的一段话，然后在调试窗口中搜索。</p><p><img src="/images/pasted-6.png" alt="upload successful"></p><p><img src="/images/pasted-7.png" alt="upload successful"><br>经过上面4步分析，我们就拿到了京东评论数据的接口：<a href="https://sclub.jd.com/comment/productPageComments.action?callback=fetchJSON_comment98vv4654&amp;productId=1263013576&amp;score=0&amp;sortType=5&amp;page=0&amp;pageSize=10&amp;isShadowSku=0&amp;fold=1" target="_blank" rel="noopener">https://sclub.jd.com/comment/productPageComments.action?callback=fetchJSON_comment98vv4654&amp;productId=1263013576&amp;score=0&amp;sortType=5&amp;page=0&amp;pageSize=10&amp;isShadowSku=0&amp;fold=1</a></p><p>productPageComments：看这个名字就知道是产品页评论</p><h3 id="2-爬取评论数据"><a href="#2-爬取评论数据" class="headerlink" title="2.爬取评论数据"></a>2.爬取评论数据</h3><p>拿到评论数据接口url之后，我们就可以开始写代码抓取数据了。一般我们会先尝试抓取一条数据，成功之后，我们再去分析如何实现大量抓取。</p><p>上一篇我们已经讲解了如何使用requests库发起http/s请求，我们来看看代码</p><p><img src="/images/pasted-8.png" alt="upload successful"></p><p>但是在打印的结果中数据却是空？为何浏览器请求成功，而我们的代码却请求不到数据呢？难道我们遇到了反爬？这种情况下如何解决？</p><p>大家在遇到这种情况时，回到浏览器的调试窗口，查看下浏览器发起的请求头，因为可能浏览器请求时携带了什么请求头参数而我们代码中没有。</p><p><img src="/images/pasted-9.png" alt="upload successful"></p><p>果然，我们在浏览器头中看到了有两个请求头Referer和User-Agent，那我们先把他们加到代码的请求头中，再试试！</p><p><img src="/images/pasted-10.png" alt="upload successful"></p><h3 id="3-数据提取"><a href="#3-数据提取" class="headerlink" title="3.数据提取"></a>3.数据提取</h3><p>我们对爬取的数据分析发现，此数据为jsonp跨域请求返回的json结果，所以我们只要把前面的fetchJSON_comment98vv4646(和最后的)去掉就拿到json数据了。</p><p><img src="/images/pasted-11.png" alt="upload successful"></p><p>将json数据复制到json格式化工具中或者在Chrome浏览器调试窗口点击Preview也可以看到，json数据中有一个key为comments的值便是我们想要的评论数据。</p><p><img src="/images/pasted-12.png" alt="upload successful"></p><p>我们再对comments值进行分析发现是一个有多条数据的列表，而列表里的每一项就是每个评论对象，包含了评论的内容，时间，id，评价来源等等信息，而其中的content字段便是我们在页面看到的用户评价内容。</p><p><img src="/images/pasted-13.png" alt="upload successful"></p><p>那我们来用代码将每个评价对象的content字段提取并打印出来</p><p><img src="/images/pasted-14.png" alt="upload successful"></p><h3 id="4-数据保存"><a href="#4-数据保存" class="headerlink" title="4.数据保存"></a>4.数据保存</h3><p>数据提取后我们需要将他们保存起来，一般保存数据的格式主要有：文件、数据库、内存这三大类。今天我们就将数据保存为txt文件格式，因为操作文件相对简单同时也能满足我们的后续数据分析的需求。</p><p><img src="/images/pasted-15.png" alt="upload successful"></p><p>然后我们查看一下生成的文件内容是否正确</p><p><img src="/images/pasted-16.png" alt="upload successful"></p><h3 id="5-批量爬取"><a href="#5-批量爬取" class="headerlink" title="5.批量爬取"></a>5.批量爬取</h3><p>再完成一页数据爬取、提取、保存之后，我们来研究一下如何批量抓取？</p><p>做过web的同学可能知道，有一项功能是我们必须要做的，那便是分页。何为分页？为何要做分页？</p><p>我们在浏览很多网页的时候常常看到“下一页”这样的字眼，其实这就是使用了分页技术，因为向用户展示数据时不可能把所有的数据一次性展示，所以采用分页技术，一页一页的展示出来。</p><p>让我们再回到最开始的加载评论数据的url：</p><p><a href="https://sclub.jd.com/comment/productPageComments.action?callback=fetchJSON_comment98vv4654&amp;productId=1263013576&amp;score=0&amp;sortType=5&amp;page=0&amp;pageSize=10&amp;isShadowSku=0&amp;fold=1" target="_blank" rel="noopener">https://sclub.jd.com/comment/productPageComments.action?callback=fetchJSON_comment98vv4654&amp;productId=1263013576&amp;score=0&amp;sortType=5&amp;page=0&amp;pageSize=10&amp;isShadowSku=0&amp;fold=1</a></p><p>我们可以看到链接里面有两个参数page=0&amp;pageSize=10，page表示当前的页数，pageSize表示每页多少条，那这两个数据直接去数据库limit数据。</p><p>老司机一眼便可以看出这就是分页的参数，但是有同学会说：如果我是老司机还干嘛看你的文章？所以我教大家如何来找到这个分页参数。</p><p>回到某东的商品页，我们将评价页面拉到最底下，发现有分页的按钮，然后我们在调试窗口清空之前的请求记录。</p><p><img src="/images/pasted-17.png" alt="upload successful"></p><p>清空之前的请求记录之后，我们点击上图红框分页按钮的数字2，代表这第二页，然后复制第一条评价去调试窗口搜索，最后找到请求链接。</p><p><img src="/images/pasted-18.png" alt="upload successful"></p><p>然后我们点击Headers查看第二页请求数据的url</p><p><img src="/images/pasted-19.png" alt="upload successful"><br>然后我们比较第一页评价与第二页评价的url有何区别</p><p><img src="/images/pasted-20.png" alt="upload successful"></p><p>这里也就验证了猪哥的猜想：page表示当前的页数，pageSize表示每页多少条。而且我们还能得出另一个结论：第一个page=0，第二页page=1 然后依次往后。有同学会问：为什么第一页不是1，而是0，因为在数据库中一般的都是从0开始计数，编程行业很多数组列表都是从0开始计数。</p><p>好了，知道分页规律之后，我们只要在每次请求时将page参数递增不就可以批量抓取了吗？我们来写代码吧！</p><p><img src="/images/pasted-21.png" alt="upload successful"></p><p>简单讲解一下做的改动：</p><p>对spider_comment方法增加入参page：</p><p>页数，然后在url中增加占位符，这样就可以动态修改url，爬取指定的页数。</p><p>增加一个batch_spider_comment方法，循环调用spider_comment方法，暂定爬取100页。</p><p>在batch_spider_comment方法的for循环中设置了一个随机的休眠时间，意在模拟用户浏览，防止因为爬取太频繁被封ip。</p><p>爬取完成之后检查成果</p><p><img src="/images/pasted-22.png" alt="upload successful"></p><p>6.数据清洗<br>数据成功保存之后我们需要对数据进行分词清洗，对于分词我们使用著名的分词库jieba。<br>首先是安装jieba库：</p><p>pip3 install jieba</p><p><img src="/images/pasted-23.png" alt="upload successful"></p><p>当然这里你还可以对一些介词等无效词进行剔除，这样可以避免无效数据。</p><p>7.生成词云<br>生成词云我们需要用到numpy、matplotlib、wordcloud、Pillow这几个库，大家先自行下载。matplotlib库用于图像处理，wordcloud库用于生成词云。</p><p><img src="/images/pasted-24.png" alt="upload successful"></p><p>注意：font_path是选择字体的路径，如果不设置默认字体可能不支持中文，猪哥选择的是Mac系统自带的宋体字！</p><p>最终结果：</p><p><img src="/images/pasted-25.png" alt="upload successful"><br>我们来看看全代码</p><p><img src="/images/pasted-26.png" alt="upload successful"></p><h2 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h2><p>因考虑新手的友好性，文章篇幅较长，详细的介绍了从需求到技术分析、爬取数据、清洗数据、最后的分析数据。我们来总结一下本篇文章学到的东西吧：</p><p>如何分析并找出加载数据的url</p><p>如何使用requests库的headers解决Referer和User-Agent反扒技术</p><p>如何找出分页参数实现批量爬取</p><p>设置一个爬虫间隔时间防止被封ip</p><p>数据的提取与保存到文件</p><p>使用jieba库对数据分词清洗</p><p>使用wordcloud生成指定形状的词云</p><p>这是一套完整的数据分析案例，希望大家能自己动手尝试，去探索更多有趣的案例，做个有趣的人～</p><p><img src="/images/pasted-27.png" alt="upload successful"></p><p>项目地址（或点击阅读原文）：</p><p><a href="https://github.com/pig6/jd_comment_spider" target="_blank" rel="noopener">https://github.com/pig6/jd_comment_spider</a></p><p>——————-End——————-</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> spyder </category>
          
      </categories>
      
      
        <tags>
            
            <tag> scrapy </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>14张思维导图，教你构建 Python核心知识体系！</title>
      <link href="/2019/08/28/14-zhang-si-wei-dao-tu-jiao-ni-gou-jian-python-he-xin-zhi-shi-ti-xi/"/>
      <url>/2019/08/28/14-zhang-si-wei-dao-tu-jiao-ni-gou-jian-python-he-xin-zhi-shi-ti-xi/</url>
      
        <content type="html"><![CDATA[<h1 id="转-14张思维导图，教你构建-Python核心知识体系！"><a href="#转-14张思维导图，教你构建-Python核心知识体系！" class="headerlink" title="[转]14张思维导图，教你构建 Python核心知识体系！"></a>[转]14张思维导图，教你构建 Python核心知识体系！</h1><p>[]: <a href="https://mp.weixin.qq.com/s?__biz=MzUzODYwMDAzNA==&amp;mid=2247487117&amp;idx=1&amp;sn=677f6d8c874e7a08494de36d69dbf4a7&amp;chksm=fad47980cda3f096c9451dc9348ec2d339f7c15dc9b072a410ef716fae50497acd0be9280fa2&amp;mpshare=1&amp;scene=1&amp;srcid=&amp;sharer_sharetime=1566975669507&amp;sharer_shareid=0dec5032e7f1662bc600d885c6062ee5&amp;key=8065703b0c5b829ad8cb3ed5703c3f81ae95105d582917b9d2dded50bf43ac84e10786c98ad96bf0838fb58dc63cf1df65a7c174c157684fdeba468f617e2f002bf5ff1c47f56af17a99429332ecf676&amp;ascene=1&amp;uin=Nzc5NjI3Njgx&amp;devicetype=Windows+7&amp;version=62060833&amp;lang=zh_CN&amp;pass_ticket=btuT7FoSlHRHn278MYUqhmO%2FGQauC00CbslWGtyTV7CiMuF6S96USI8fHd1BHPmN" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzUzODYwMDAzNA==&amp;mid=2247487117&amp;idx=1&amp;sn=677f6d8c874e7a08494de36d69dbf4a7&amp;chksm=fad47980cda3f096c9451dc9348ec2d339f7c15dc9b072a410ef716fae50497acd0be9280fa2&amp;mpshare=1&amp;scene=1&amp;srcid=&amp;sharer_sharetime=1566975669507&amp;sharer_shareid=0dec5032e7f1662bc600d885c6062ee5&amp;key=8065703b0c5b829ad8cb3ed5703c3f81ae95105d582917b9d2dded50bf43ac84e10786c98ad96bf0838fb58dc63cf1df65a7c174c157684fdeba468f617e2f002bf5ff1c47f56af17a99429332ecf676&amp;ascene=1&amp;uin=Nzc5NjI3Njgx&amp;devicetype=Windows+7&amp;version=62060833&amp;lang=zh_CN&amp;pass_ticket=btuT7FoSlHRHn278MYUqhmO%2FGQauC00CbslWGtyTV7CiMuF6S96USI8fHd1BHPmN</a><br>本文主要涵盖了 Python 编程的核心知识（暂不包括标准库及第三方库）。</p><pre><code>1. 按顺序依次展示了以下内容的一系列思维导图：基础知识，数据类型（数字，字符串，列表，元组，字典，集合），条件&amp;循环，文件对象，错误&amp;异常，函数，模块，面向对象编程；2. 结合这些思维导图主要参考的资料，分享一下我的学习体验，一方面可供初学者参考，另一方面，也便于大家结合思维导图深入学习、理解、思考；</code></pre><h2 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h2><p><img src="http://ww1.sinaimg.cn/large/006Dl8bFly1g6fes9k4onj30u00qwab8.jpg" alt=""></p><h3 id="14张思维导图"><a href="#14张思维导图" class="headerlink" title="14张思维导图"></a>14张思维导图</h3><p>1.第一张<br>        基础知识图一包括了基本规则、Python语言特点、计算机语言、如何运行Python、变量赋值五个方面，辅助你快速掌握Python编程的基底知识。<br><img src="https://raw.githubusercontent.com/byq-luo/tp/master/blog_files/img/PicGo-Github-PicBed/20190830084716.png" alt=""><br>2.第二张<br>        基础知识图二包含了模块结构、布局、IO编程流程、标识符、Python对象、内存管理、动态类型六大模块，两张基础知识导图可以帮助你区域化了解Python的组成部分及基本操作。<br><img src="http://pwzi6d4jn.bkt.clouddn.com/img/20190830/VJTLjnsI1Fjt.png?imageslim" alt="mark"><br>3.第三张<br>        学习Python少不了对数据的了解，这张图整理了数据类型的分类、作用、空值、标准数据、if语句等等模块。<br><img src="http://pwzi6d4jn.bkt.clouddn.com/img/20190830/I8r4dtUmxstV.png?imageslim" alt="mark"><br>4.第四张<br>        这张图整理了序列的有序排列、标准操作符与序列类型操作符的重点知识，以及可操作性的BIF。<br><img src="http://pwzi6d4jn.bkt.clouddn.com/img/20190830/nE6ubexfD47d.png?imageslim" alt="mark"><br>5.第五张<br>        字符串是个比较庞大而精细的部分，接着上图的BIF可分为标准类型、序列类型、字符串类型，字符串可分为五种操作符类型，此图还整理了序列的独特特性以及编码问题，可以说很详细了。<br><img src="http://pwzi6d4jn.bkt.clouddn.com/img/20190830/zOnyEXUV9zy8.png?imageslim" alt="mark"><br>6.第六张<br>        关于列表|元素，首先说拷贝问题，分深浅拷贝两种形式。tuple的内建函数、特殊特性与list的操作符、内建函数是重点部分。<br><img src="http://pwzi6d4jn.bkt.clouddn.com/img/20190830/wmq1JwlUuVTS.png?imageslim" alt="mark"><br>7.第七张<br>    这张图主要整理了字典|集合中set、dict的功能、分类、BIF、操作问题。<br><img src="http://pwzi6d4jn.bkt.clouddn.com/img/20190830/VsN7Xyp7pMdd.png?imageslim" alt="mark"><br>8.第八张<br>        条件|循环包含生成器、迭代器、列表解析的使用、拓展，相关BIF、if语句循环控制也能够快速掌握重点。<br><img src="http://pwzi6d4jn.bkt.clouddn.com/img/20190830/7JyijnV0Mypa.png?imageslim" alt="mark"><br>9.第九张<br>        关于文件对象内建方法、内建函数、内建属性都有具体内容，文件迭代的运用，标准文件对象如何输入输出以及分隔符的运用都在导图中详细标明。<br><img src="http://pwzi6d4jn.bkt.clouddn.com/img/20190830/Ftz2KgBTtCv5.png?imageslim" alt="mark"><br>10.第十张<br>        错误|异常这张图的点介绍了如何调试、处理异常情况。<br><img src="http://pwzi6d4jn.bkt.clouddn.com/img/20190830/xFwJPrT0WQKc.png?imageslim" alt="mark"><br>11.第十一张<br>        函数一介绍了函数概述，注意vs函数的引用、调用，装饰器的定义、“堆叠”。参数具有自己的完整语法以及自己的传递方式。<br><img src="http://pwzi6d4jn.bkt.clouddn.com/img/20190830/MB2CG09sSVcE.png?imageslim" alt="mark"><br>12.第十二张<br>        函数二图整理了递归函数、返回（回调）函数、变量作用域、偏函数、函数式编程、匿名函数、高阶函数BIF的详细介绍。<br><img src="http://pwzi6d4jn.bkt.clouddn.com/img/20190830/Mtk7v57idIxr.png?imageslim" alt="mark"><br>13.第十三张<br>        这张图的重点是模块的标准区域、名称空间以及模块的作用域（三种变量的运用）。<br><img src="http://pwzi6d4jn.bkt.clouddn.com/img/20190830/RliTRvDEAHIF.png?imageslim" alt="mark"><br>14.第十四张<br>        最后一张图整理了面向对象编程，弄清楚面向对象的基本概念，继承与多态、结构组织以及对象的性质、访问限制等重点，对于python就算是入门了。<br><img src="http://pwzi6d4jn.bkt.clouddn.com/img/20190830/V30OPc5S6sOx.png?imageslim" alt="mark"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python体系 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pandas </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>交通预测新视角 - 基于 GCN 的出租车 OD 需求预测</title>
      <link href="/2019/08/26/jiao-tong-yu-ce-xin-shi-jiao-ji-yu-gcn-de-chu-zu-che-od-xu-qiu-yu-ce/"/>
      <url>/2019/08/26/jiao-tong-yu-ce-xin-shi-jiao-ji-yu-gcn-de-chu-zu-che-od-xu-qiu-yu-ce/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文由 <a href="http://ksria.com/simpread/" target="_blank" rel="noopener">简悦 SimpRead</a> 转码， 原文地址 <a href="https://mp.weixin.qq.com/s?__biz=Mzg4MTE4ODQ3MA==&amp;mid=2247484047&amp;idx=1&amp;sn=7f47b3acc84d59d8272f392ae77ec263&amp;chksm=cf688996f81f0080a9bb6e533d80acabd07dc52f494b805cfdfdc7f8bc9ba736302155abe242&amp;scene=0&amp;xtrack=1&amp;key=dd5051400a9fb58fd42734976fb4891e399d9a8fd01a1d26d1e8a711b3810cc7d2455721ebf91add938a0e646769762f781adc1da3a01ef3ca49c3dcf8dc252eb7994f9850f2d5d6a6674405053cd854&amp;ascene=1&amp;uin=Nzc5NjI3Njgx&amp;devicetype=Windows+7&amp;version=62060833&amp;lang=zh_CN&amp;pass_ticket=0D2i7tjRttrD043Y7F4kCHwZJzqgJzkLTPsgkirjBZi1ERON%2Bm%2FzBZkrpJsAOSE5" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=Mzg4MTE4ODQ3MA==&amp;mid=2247484047&amp;idx=1&amp;sn=7f47b3acc84d59d8272f392ae77ec263&amp;chksm=cf688996f81f0080a9bb6e533d80acabd07dc52f494b805cfdfdc7f8bc9ba736302155abe242&amp;scene=0&amp;xtrack=1&amp;key=dd5051400a9fb58fd42734976fb4891e399d9a8fd01a1d26d1e8a711b3810cc7d2455721ebf91add938a0e646769762f781adc1da3a01ef3ca49c3dcf8dc252eb7994f9850f2d5d6a6674405053cd854&amp;ascene=1&amp;uin=Nzc5NjI3Njgx&amp;devicetype=Windows+7&amp;version=62060833&amp;lang=zh_CN&amp;pass_ticket=0D2i7tjRttrD043Y7F4kCHwZJzqgJzkLTPsgkirjBZi1ERON%2Bm%2FzBZkrpJsAOSE5</a></p></blockquote><blockquote><p>今天周末啦，明天又是新的一周，时间过得好快哦，晚上和同学出去吃了饭，很开森！发完文章就休息啦，晚安~</p></blockquote><p>1、文章信息</p><p>《Origin-Destination Matrix Prediction via Graph Convolution: a New Perspective of Passenger Demand Modeling》。</p><p>北航计算机学院发在 2019KDD 上的一篇论文。</p><p>2、摘要</p><p>为了获得乘客的出行模式，打车平台需要提前预测一个地区到另一个地区的乘客需求数量，即 OD 矩阵预测 (ODMP) 问题。OD 矩阵预测比普通需求预测更具挑战性。除了要预测一个地区的需求产生量，还需要预测需求的目的地。此外，数据稀疏性是一个严重的问题。因此本文提出了一种基于网格嵌入的单馈多任务学习模型(GEML)。该模型主要包含两个部分，分别提取时间信息和空间信息。网格嵌入部分是为了对乘客的空间移动模式和不同区域的相邻关系进行建模，其预加权聚合器的目的是感知数据的稀疏性和范围；多任务学习部分则侧重于时间属性建模和捕获 ODMP 问题目标。两个数据集 - UCAR 和 Didi - 的结果表明 GEML 方法优于基准模型。</p><p>3、简介</p><p>除了预测某一区域内可能的乘客需求数量外，了解每次出行的来源地和目的地的乘客需求也很重要。因为不同时段两个区域之间的需求量不仅承载着乘客需求的强度，而且有利于挖掘有用的出行模式。本文从一个新的角度研究了乘客需求模型，即 OD 矩阵预测（ODMP）。OD 矩阵包含两个方面的信息: (1) 不同的 OD 组合; (2) 每个 OD 对的旅客需求数量。ODMP 的目标是预测在给定时间段内从一个地理区域到另一个地理区域的叫车订单数量。为了同时兼顾出行产生量和目的地，时空特性以及数据稀疏性，本文提出了一种基于网格嵌入的单馈多任务学习模型 (GEML)，以基于图对出行模式进行建模。具体来说，我们用图表示与地理区域相关的乘客订单记录，其中节点表示地理区域 (以网格形式定义)，节点之间的边表示乘客需求，边权重表示订单数量。利用改进后的网格，可以构造出给定时间间隔内的 OD 矩阵。如图 1 所示，将区域划分为 16 个网格，订单记录汇总在相应的 OD 矩阵中。</p><p><img src="/.io//%5Cimages%5Cpasted-29.png" alt="upload successful"></p><p>本文模型的灵感来自于最近大火的 GCNs，然而如果我们直接将已有的 GCNs 应用到 OD 矩阵所生成的图上，由于数据稀疏，学习到的具有很少订单的网格嵌入往往是不可靠和无效的，此外，如果没有任何历史订单记录的孤立节点 (例如，新建社区)，学习到的网格嵌入也是不可行的 (无论作为 O 点还是 D 点)。为了缓解数据的稀疏性问题，我们提出基于地理学第一定律探索网格的地理相关性，即所有的东西都是相关的，但附近的东西比遥远的东西更相关。例如，在两个地理位置相近的网格中，乘客需求的数量往往接近彼此。特别地，我们考虑了网格嵌入部分的两种邻域，即地理邻域（地理上相邻的）和语义领域（通过 OD 流连接起来的）。前者用于度量一个网格与其邻域之间的内在紧密程度，后者用于对网络 OD 之间的交通流强度建模。</p><p>基于网格嵌入学习得到的网格的表示，结合乘客需求的重要时间信息，设计了一个面向 ODMP 的多任务神经网络。受既有工作的启发，我们对一个网格的流入流和流出流分别建模，预测每个网格在不同时间段的流入和流出需求数量。引入这两个子任务的基本原理是，我们能够在每个网格上单独捕获更多的动态出行模式。通过补充两个单独的子任务，总体需求预测任务可以捕获更强的内在时间模式，因为每个网格中的总体需求具有更大的规模或粒度。例如，在早高峰时段，当网格划分的粒度很小时，网约车需求的目的地可能存在很大不同，导致数据稀疏性问题，这意味着乘客需求的目的地可能分布得非常广泛，但这些网格的总流入流和流出流是非常大的。</p><p>本文主要贡献如下：</p><p>（1）提出 OD 矩阵预测问题预测给定时间段内的 OD 乘客需求，这对于网约车平台运营管理具有重要意义。</p><p>（2）将研究区域划分为网格，设计了网格嵌入网络，通过在新定义的网格邻域 (地理和语义邻域) 之间的图卷积，对每个网格进行嵌入，该网络通过模仿 GCNs 中的信息传递模式来模拟不同网格之间的 OD 流关系。</p><p>（3）借助 LSTM 设计了一个多任务学习网络用于捕捉乘客需求的时间趋势。两个子任务预测网格中的单个流入流和流出流需求，而主任务预测每对网格之间的需求。</p><p>（4）在两个真实大规模叫车数据集上的大量实验表明提出的 GEML 模型性能优于基准模型。</p><p>4、模型框架</p><p><img src="/.io//%5Cimages%5Cpasted-30.png" alt="upload successful"></p><p>GEML 模型能同时捕获空间和时间特性。从空间角度出发，提出了一种基于邻域的网格嵌入方法，通过聚集邻域信息来学习每个网格的向量表示。从时间的角度，我们设计了一个多任务学习框架来模拟乘客需求随时间的动态趋势。接下来，我们将介绍网格嵌入和多任务学习的技术细节。</p><p>4.1 Grid Embedding</p><p>在 ODMP 环境下，提出了网格嵌入部分的两种邻域，即地理邻域（地理上相邻的）和语义领域（通过 OD 流连接起来的）。前者用于度量一个网格与其邻域之间的内在紧密程度，后者用于对网络 OD 之间的交通流强度建模，如图所示。</p><p><img src="/.io//%5Cimages%5Cpasted-31.png" alt="upload successful"></p><p>（1）Geographical Neighborhood</p><p>两个区域中心点之间的距离小于一定的阈值可定义为地理邻域。</p><p><img src="/.io//%5Cimages%5Cpasted-32.png" alt="upload successful"></p><p>（2）Semantic Neighborhood</p><p>如果两个区域之间至少有一个 OD 流 (可以是相反方向), 即可定义为两者为语义邻域。在任意时间段 t′= 1, 2,…，我们可以通过公式 2 获取网格 i 的语义邻域。由式 (2) 可知，不同网格在不同时间间隔的语义邻居个数是不确定的。由于 ODMP 问题对时间敏感，因此考虑不同网格在不同时间间隔的语义关系至关重要。</p><p><img src="/.io//%5Cimages%5Cpasted-33.png" alt="upload successful"></p><p>（3）Pre-Weighted Aggregator for Grid Embedding</p><p>我们通过聚合地理邻域Φ和语义邻域Ω推断每个网格的向量表示，我们不是为每个网格训练一个不同的嵌入向量，而是训练一个聚合器函数，它学会从网格的邻域中积累和选择特征信息。在详细介绍用于网格嵌入的预加权聚合器之前，我们首先简要介绍 [10] 采用的朴素聚合器形式：</p><p><img src="/.io//%5Cimages%5Cpasted-34.png" alt="upload successful"></p><p>vi 是网格 gi 的嵌入向量，MEAN(·) 表示对应元素均值，vj 是网格 gj 的嵌入向量, 朴素聚合方法即是计算 vi’和 vj’对应元素的均值，并将它们连接到之前的特性 vi’。 然而，尽管有一些基本聚合器的变体 (例如 pooling aggregator and LSTM aggregator)，现有的图卷积聚合方法在 ODMP 场景下缺乏充分捕捉不同网格之间关系的能力，无法进行需求建模，原因是这些聚合器在融合每个网格邻居的所有特性时无法区分它们的重要性，直观地说，两个网格之间的地理距离越近，它们的属性就越相似。此外，在语义邻居集中，邻居网格的受欢迎程度应该对聚合过程产生影响，因为它保留了具有代表性的出行模式。</p><p>在此基础上，提出了一种预加权聚合器，该聚合器可以选择性地将重点放在网格嵌入的重要邻域上。对于网格的地理邻域，我们利用相邻区域之间的距离作为聚合器的权重因子。因此，我们将地理邻域的预加权聚合器表示为：</p><p><img src="/.io//%5Cimages%5Cpasted-35.png" alt="upload successful"></p><p>对于语义邻域，degree 代表 OD 流量，即两个区域之间的 OD 流（从 i 到 j 或从 j 到 i），ϵ是一个非常小的值接近于零, 以防 degree(gj) = 0。</p><p><img src="/.io//%5Cimages%5Cpasted-36.png" alt="upload successful"></p><p>注意，两种表示都是随时间变化的，是一个动态指标。最后，将两种语义表示连接起来得到一个网格最终的语义表示。</p><p><img src="/.io//%5Cimages%5Cpasted-37.png" alt="upload successful"></p><p>4.2 Multi-Task Learning</p><p>本节出了一种具有 periodic-skip LSTM 的多任务学习方案，如图 4 所示。</p><p><img src="/.io//%5Cimages%5Cpasted-38.png" alt="upload successful"></p><p>(1) Periodic-Skip LSTM</p><p><img src="/.io//%5Cimages%5Cpasted-39.png" alt="upload successful"></p><p>为了全面了解乘客需求的动态模式，我们从 UCAR 数据集中随机抽取了 5 天，并在图 5 中绘制了每天的每小时乘客需求。</p><p><img src="/.io//%5Cimages%5Cpasted-40.png" alt="upload successful"></p><p>显然，与此同时，乘客需求的数量也有类似的模式。然而，在预测下一小时的乘客需求时，LSTM 中的序列建模方案将迫使模型从之前的连续小时中收集信息。这可能对需求预测没有多大帮助，因为不相关的输入会产生很多噪音。为此，为了更好地对周期性进行建模，我们取网格嵌入序列 {vi1, vi2，…， vit} 作为输入，进一步将 Eq.(8)转换为 Periodic-Skip LSTM，跳过不相关的顺序模式。</p><p><img src="/.io//%5Cimages%5Cpasted-41.png" alt="upload successful"></p><p>其中 p 是跳过的隐藏状态数。</p><p>（2）main task</p><p>由 periodic-skip LSTM 框架, 我们可以得到在时间 t 网格 gi 的向量表示。为了得到 OD 矩阵中每一项 mij 的值，我们构造了一个过渡矩阵 Wm∈R（d×d）以对 OD 流进行建模。此时，预测值 m 可由下式计算。损失函数为均方误差。</p><p><img src="/.io//%5Cimages%5Cpasted-42.png" alt="upload successful"></p><p><img src="/.io//%5Cimages%5Cpasted-43.png" alt="upload successful"></p><p>（3）Two Subtasks: Predicting the In- and Out-Degrees</p><p>在预测上述总体 OD 矩阵的主要任务的同时，我们还分别对流入流（p）和流出流（q）进行了建模。其中 Win 和 Wout 是用于将网格嵌入投影到标量的两个投影权重。损失函数为均方误差，G 是网格的个数。</p><p><img src="/.io//%5Cimages%5Cpasted-44.png" alt="upload successful"></p><p><img src="/.io//%5Cimages%5Cpasted-45.png" alt="upload successful"><br>（4）损失函数</p><p>针对上述三个任务，我们将主要任务的损失和两个子任务的损失结合起来，制定出总体损失函数。</p><p><img src="/.io//%5Cimages%5Cpasted-46.png" alt="upload successful"></p><p>实验部分不再详述。</p><p>5、总结</p><p>总体而言，文章的研究角度确实很新，值得借鉴。但这篇文章仍有一个致命弱点，即没有考虑行程时间，由 O 点到 D 点需要一定的行程时间，因此实时的 OD 矩阵是不可能得到的，因此利用真实的历史 OD 矩阵作为输入在实时预测中是不可行的。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 算法 </tag>
            
            <tag> Traffic </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>来! 一起捋一捋机器学习分类算法</title>
      <link href="/2019/08/23/ji-qi-xue-xi-fen-lei-suan-fa/"/>
      <url>/2019/08/23/ji-qi-xue-xi-fen-lei-suan-fa/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文由 <a href="http://ksria.com/simpread/" target="_blank" rel="noopener">简悦 SimpRead</a> 转码， 原文地址 <a href="https://mp.weixin.qq.com/s?__biz=MzAwOTQ4MzY1Nw==&amp;mid=2247488683&amp;idx=2&amp;sn=e42d5e49238ef2208dc9ab96eb86bef9&amp;chksm=9b5fb04dac28395bc669ab031a3b9603712bebb4506dd0248dca263db828c6930773a17d7dc8&amp;scene=0&amp;xtrack=1&amp;key=dd5051400a9fb58f37315809ce7677223523738fdd5013166a6dee9c14c5d49a33229d83dce5ae38fc2666e443b5d9286227f98f41137bbb6c31e7c232fc1ac2c49641b4513b3e2c0a19522cbe1df716&amp;ascene=1&amp;uin=Nzc5NjI3Njgx&amp;devicetype=Windows+7&amp;version=62060833&amp;lang=zh_CN&amp;pass_ticket=MX7U8Edx%2Br4NOEKnFQ4xLReRonwghtAP4C2EWKwp98c0df25UJ96hbKCmcxYcVM6" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzAwOTQ4MzY1Nw==&amp;mid=2247488683&amp;idx=2&amp;sn=e42d5e49238ef2208dc9ab96eb86bef9&amp;chksm=9b5fb04dac28395bc669ab031a3b9603712bebb4506dd0248dca263db828c6930773a17d7dc8&amp;scene=0&amp;xtrack=1&amp;key=dd5051400a9fb58f37315809ce7677223523738fdd5013166a6dee9c14c5d49a33229d83dce5ae38fc2666e443b5d9286227f98f41137bbb6c31e7c232fc1ac2c49641b4513b3e2c0a19522cbe1df716&amp;ascene=1&amp;uin=Nzc5NjI3Njgx&amp;devicetype=Windows+7&amp;version=62060833&amp;lang=zh_CN&amp;pass_ticket=MX7U8Edx%2Br4NOEKnFQ4xLReRonwghtAP4C2EWKwp98c0df25UJ96hbKCmcxYcVM6</a></p></blockquote><p>（点击上方快速关注并设置为星标，一起学 Python）  </p><blockquote><p>大数据文摘出品              来源：builtin</p><p>编译：邢畅、刘兆娜、李雷、钱天培   链接：</p><p><a href="https://mp.weixin.qq.com/s/hN73sdADY--LnUh7Bo9G5Q" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/hN73sdADY--LnUh7Bo9G5Q</a></p></blockquote><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/wc7YNPm3YxUNorwGD42Y64wzgalSpEC59Hqibqouy3ACtz1WZBdWbbdtUFMZWZYDutWk1S6sskEBwkdR8GyFEBQ/640?wx_fmt=jpeg" alt=""></p><p>说起分类算法，相信学过机器学习的同学都能侃上一二。</p><p>可是，你能够如数家珍地说出所有常用的分类算法，以及他们的特征、优缺点吗？比如说，你可以快速地回答下面的问题么:</p><ul><li><p>KNN 算法的优缺点是什么？</p></li><li><p>Naive Bayes 算法的基本假设是什么？</p></li><li><p>entropy loss 是如何定义的？</p></li><li><p>最后，分类算法调参常用的图像又有哪些？</p></li></ul><p>答不上来？别怕！一起来通过这篇文章回顾一下机器学习分类算法吧（本文适合已有机器学习分类算法基础的同学）。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_gif/fgnkxfGnnkQib1uHZcwStG0BEXmInia1TL9HicHmMCQibVaPqjaaOOgVnP0KxcPKPaFvRXP2jksM8pOPqNnIMD3CAQ/640?wx_fmt=gif" alt=""></p><hr><p>机器学习是一种能从数据中学习的计算机编程科学以及艺术，就像下面这句话说得一样。</p><blockquote><p>机器学习是使计算机无需显式编程就能学习的研究领域。</p><p>——阿瑟 · 塞缪尔，1959 年</p></blockquote><p>不过还有一个更好的定义：</p><blockquote><p>“如果一个程序在使用既有的经验（E）执行某类任务（T）的过程中被认为是 “具备学习能力的”，那么它一定需要展现出: 利用现有的经验（E），不断改善其完成既定任务（T）的性能（P）的特性。”</p><p>——Tom Mitchell, 1997</p></blockquote><p>例如，你的垃圾邮件过滤器是一个机器学习程序，通过学习用户标记好的垃圾邮件和常规非垃圾邮件示例，它可以学会标记垃圾邮件。系统用于学习的示例称为训练集。在此案例中，任务（T）是标记新邮件是否为垃圾邮件，经验（E）是训练数据，性能度量（P） 需要定义。例如，你可以定义正确分类的电子邮件的比例为 P。这种特殊的性能度量称为准确度，这是一种有监督的学习方法，常被用于分类任务。</p><p>机器学习入门指南：</p><p><a href="https://builtin.com/data-science/introduction-to-machine-learning" target="_blank" rel="noopener">https://builtin.com/data-science/introduction-to-machine-learning</a></p><p>监督学习</p><hr><p>在监督学习中，算法从有标记数据中学习。在理解数据之后，该算法通过将模式与未标记的新数据关联来确定应该给新数据赋哪种标签。</p><p>监督学习可以分为两类：<strong>分类</strong>和<strong>回归</strong>。</p><p><strong>分类问题预测数据所属的类别；</strong></p><p>分类的例子包括垃圾邮件检测、客户流失预测、情感分析、犬种检测等。</p><p><strong>回归问题根据先前观察到的数据预测数值；</strong></p><p>回归的例子包括房价预测、股价预测、身高 - 体重预测等。</p><p>机器学习新手的十大算法之旅：</p><p><a href="https://builtin.com/data-science/tour-top-10-algorithms-machine-learning-newbies" target="_blank" rel="noopener">https://builtin.com/data-science/tour-top-10-algorithms-machine-learning-newbies</a></p><p>分类问题</p><hr><p>分类是一种基于一个或多个自变量确定因变量所属类别的技术。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxXKEyiadtvyXhicxUJJj68hlgrMapic3Jj4xwADMjv2MiamPXibib8aEXFhLIUpAM45lmdchF8bmUCorNBg/640?wx_fmt=png" alt="">  </p><p>分类用于预测离散响应</p><p>### </p><p>逻辑回归</p><p>逻辑回归类似于线性回归，适用于因变量不是一个数值字的情况 (例如，一个 “是 / 否” 的响应)。它虽然被称为回归，但却是基于根据回归的分类，将因变量分为两类。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/wc7YNPm3YxVLqHcJer966XtEVlwdKia9JHUMs4fW48h48cukNCic2x4lg9dcnoORMu9EtJLWNrJ0MKkLH4icO7HJg/640?wx_fmt=jpeg" alt=""></p><p>如上所述，逻辑回归用于预测二分类的输出。例如，如果信用卡公司构建一个模型来决定是否通过向客户的发行信用卡申请，它将预测客户的信用卡是否会 “违约”。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxUNorwGD42Y64wzgalSpEC5e9Fjh1ZoROzAh5ibPbISCUc2XIZn020iaWRtiapDVnic7ZYiaBypqTibBmicw/640?wx_fmt=png" alt=""></p><p>首先对变量之间的关系进行线性回归以构建模型，分类的阈值假设为 0.5。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxUNorwGD42Y64wzgalSpEC5v6iceH1eOo0EXBjhbkyR6VmtuZK09NVz3hemaqvv8ib4V9EG72rGEGag/640?wx_fmt=png" alt=""></p><p>然后将 Logistic 函数应用于回归分析，得到两类的概率。</p><p>该函数给出了事件发生和不发生概率的对数。最后，根据这两类中较高的概率对变量进行分类。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxVLqHcJer966XtEVlwdKia9JNftGXWRqn0kDtKEKGNzTvA4HicAEPJ9gpUXJFYKo0rpamqeNyeiaQdkw/640?wx_fmt=png" alt=""></p><p>### </p><p>K - 近邻算法（K-NN）</p><p>K-NN 算法是一种最简单的分类算法，通过识别被分成若干类的数据点，以预测新样本点的分类。K-NN 是一种非参数的算法，是 “懒惰学习” 的著名代表，它根据相似性（如，距离函数）对新数据进行分类。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxVLqHcJer966XtEVlwdKia9JOQWVWkvrgkzN05ib4GFQ330os5JrXo0fYOrIV6Z86UPrjlFfanRLaWg/640?wx_fmt=png" alt=""></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxU95ztWMrZJ4Pib02XznYG2CRrDaaaOqYPZeS0xKyZhlIK8hsDeWibEeQ3ibuCVFjACrtSNSuDRrqxHg/640?wx_fmt=png" alt=""><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxU95ztWMrZJ4Pib02XznYG2CLztpWBEr4Ol6ThicyJTvd9Xk3e8iaOgpL3OC9Ky8uHnHq9eziaorcwhAg/640?wx_fmt=png" alt=""></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxU95ztWMrZJ4Pib02XznYG2CaoW6pGuyWN94CKqLV1emWAnF7oZfmyDkVICdUbYhBQ0Ot5zscr54Tg/640?wx_fmt=png" alt=""></p><p>K-NN 能很好地处理少量输入变量（p）的情况，但当输入量非常大时就会出现问题。</p><p>### </p><p>支持向量机（SVM）</p><p>支持向量机既可用于回归也可用于分类。它基于定义决策边界的决策平面。决策平面（超平面）可将一组属于不同类的对象分离开。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxU95ztWMrZJ4Pib02XznYG2CqEz4c1yV0HQEEv4PuicCmPlwwtFIiavFZt2BT2XEHsGicLQfO0PWFzmSQ/640?wx_fmt=png" alt=""></p><p>在支持向量的帮助下，SVM 通过寻找超平面进行分类，并使两个类之间的边界距离最大化。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxU95ztWMrZJ4Pib02XznYG2CtSDRnrK8HCnJm39VHkFGpco9lo0xHicskwEYF6zpXGFBkaP4rngdg8w/640?wx_fmt=png" alt=""></p><p>SVM 中超平面的学习是通过将问题转化为使用一些某种线性代数转换问题来完成的。（上图的例子是一个线性核，它在每个变量之间具有线性可分性）。</p><p>对于高维数据，使用可使用其他核函数，但高维数据不容易进行分类。具体方法将在下一节中阐述。</p><p><strong>核支持向量机</strong></p><p>核支持向量机将核函数引入到 SVM 算法中，并将其转换为所需的形式，将数据映射到可分的高维空间。</p><p>核函数的类型包括：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxUNorwGD42Y64wzgalSpEC56ibLYibcCy6k1rUSI9R3O3h5ibkE0m1FZ1ldWvBAib6GSX0pRDRUmpiaJcQ/640?wx_fmt=gif" alt=""></p><ul><li><p>前文讨论的就是<strong>线性 SVM</strong>。</p></li><li><p><strong>多项式核</strong>中需要指定多项式的次数。它允许在输入空间中使用曲线进行分割。</p></li><li><p><strong>径向基核</strong>（radial basis function, RBF）可用于非线性可分变量。使用平方欧几里德距离，参数的典型值会导致过度拟合。sklearn 中默认使用 RBF。</p></li><li><p>类似于与逻辑回归类似，<strong>sigmoid 核</strong>用于二分类问题。</p></li></ul><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxU95ztWMrZJ4Pib02XznYG2CiciaISvcaCgUuyDYnY2wt76S7Qic055JpuwiaTTp0uVbskuGKnqeF7mFMQ/640?wx_fmt=png" alt=""></p><p><strong>径向基核（RBF：**</strong>Radial Basis Function ）**</p><p>RBF 核支持向量机的决策区域实际上也是一个线性决策区域。RBF 核支持向量机的实际作用是构造特征的非线性组合，将样本映射到高维特征空间，再利用线性决策边界分离类。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxU95ztWMrZJ4Pib02XznYG2C1hp5Blia6ibVqlJdVoFJ880iaSyia3xJwSO6qB37avdozF50WLDeBKfacA/640?wx_fmt=png" alt=""></p><p>因此，可以得出经验是：对线性问题使用线性支持向量机，对非线性问题使用非线性核函数，如 RBF 核函数。</p><p>### </p><p>朴素贝叶斯</p><p>朴素贝叶斯分类器建立在贝叶斯定理的基础上，基于特征之间互相独立的假设（假定类中存在一个与任何其他特征无关的特征）。即使这些特征相互依赖，或者依赖于其他特征的存在，朴素贝叶斯算法都认为这些特征都是独立的。这样的假设过于理想，朴素贝叶斯因此而得名。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxXKEyiadtvyXhicxUJJj68hlgnHqI67G1EiafJNzH4mn8mUrOsI33ibQVdqlkFzlYCcHaUoibJRpeicJEkA/640?wx_fmt=png" alt=""></p><p>在朴素贝叶斯的基础上，高斯朴素贝叶斯根据二项（正态）分布对数据进行分类。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxU95ztWMrZJ4Pib02XznYG2C3zPxuhwFmkSYxULW2OIVLia9m5B6eaJOpWXKfyKTIOVcfVVIzIetkDg/640?wx_fmt=png" alt=""></p><p><strong>P(class|data)</strong> 表示给定特征（属性）后数据属于某类（目标）的后验概率。给定数据，其属于各类的概率大小就是我们要计算的值。</p><p><strong>P(class)</strong> 表示某类的先验概率。</p><p><strong>P(data|class)</strong> 表示似然，是指定类别时特征出现的概率。</p><p><strong>P(data)</strong> 表示特征或边际似然的先验概率。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxUNorwGD42Y64wzgalSpEC5H96dTOCkyhAaewAUOh3okNRdABptPNeykjTbopGaeCR8TuVFxSzSkg/640?wx_fmt=png" alt="">   </p><p><strong>步骤</strong></p><p><strong>1、计算先验概率</strong></p><p>P(class) = 类中数据点的数量 / 观测值的总数量</p><p>P(yellow) = 10/17</p><p>P(green) = 7/17</p><p><strong>2、计算边际似然</strong></p><p>P(data) = 与观测值相似的数据点的数量 / 观测值的总数量</p><p>P(?) = 4/17</p><p>该值用于检查各个概率。</p><p><strong>3、计算似然</strong></p><p>P(data/class) = 类中与观测值相似的数量 / 类中点的总数量</p><p>P(?/yellow) = 1/7</p><p>P(?/green) = 3/10</p><p><strong>4、计算各类的后验概率</strong></p><pre><code>   ![](https://mmbiz.qpic.cn/mmbiz_jpg/wc7YNPm3YxUNorwGD42Y64wzgalSpEC5lic2WVh1xQ7cjVw8SdsThRiasEuyJgUic9M3cr8GDhLmKSc78e3MzznJQ/640?wx_fmt=jpeg)</code></pre><p><strong>5、分类</strong></p><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/wc7YNPm3YxUNorwGD42Y64wzgalSpEC5ZcRVGXSnCm4uJLYHGmlyxQDvkO5vCItcEaficdsOCP3PXyibSgg0j77w/640?wx_fmt=jpeg" alt=""></p><p>某一点归于后验概率高的类别，因为从上可知其属于绿色类的概率是 75% 根据其 75% 的概率这个点属于绿色类。</p><p>多项式、伯努利朴素贝叶斯是计算概率的其他模型。朴素贝叶斯模型易于构建，不需要复杂的参数迭代估计，这使得它对非常大的数据集特别有用。</p><p>### </p><p>决策树分类</p><p><strong>决策树以树状结构构建分类或回归模型**</strong>。<strong>它通过将数据集不断拆分为更小的子集来使决策树不断生长。最终长成具有决策节点（包括根节点和内部节点）和叶节点的树。最初决策树算法它采用采用 **Iterative Dichotomiser 3（ID3）</strong>算法来确定分裂节点的顺序。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxXKEyiadtvyXhicxUJJj68hlgoE7IyuExpCf7TEDQDNUdqvRF5oOvudiatuicWroXiaZSliaQhlFXOrcdbA/640?wx_fmt=png" alt=""></p><p>信息熵和信息增益用于被用来构建决策树。</p><p><strong>信息熵</strong></p><p>信息熵是衡量元素无序状态程度的一个指标，即衡量信息的不纯度。</p><pre><code>   ![](https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxUNorwGD42Y64wzgalSpEC5msIicS5yvaTAtzQPKqiaMewdcczibPfw5YCyMPkyuXzFJr3pRgc4raJLw/640?wx_fmt=png)      </code></pre><p>信息熵是衡量元素的无序状态的程度的一个指标，或者说，衡量信息的不纯度。</p><pre><code>   ![](https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxUNorwGD42Y64wzgalSpEC5msIicS5yvaTAtzQPKqiaMewdcczibPfw5YCyMPkyuXzFJr3pRgc4raJLw/640?wx_fmt=png)      </code></pre><p>直观上说地理解，信息熵表示一个事件的确定性程度。信息熵度量样本的同一性，如果样本全部属于同一类，则信息熵为 0；如果样本等分成不同的类别，则信息熵为 1。</p><p><strong>信息增益</strong></p><p>信息增益测量独立属性间信息熵的变化。它试图估计每个属性本身包含的信息，构造决策树就是要找到具有最高信息增益的属性（即纯度最高的分支）。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxUNorwGD42Y64wzgalSpEC5EuvLnSA3xtibdkIbR7BE5hT3h6rOn8D4ZyMEsal3iaAyaKkpNVkXCbOg/640?wx_fmt=png" alt=""></p><p>信息增益测量独立属性间的信息熵的变化。它试图估计每个属性本身包含的信息，构造决策树就是要找到具有最高信息增益的属性（即纯度最高的分支）。</p><pre><code>   ![](https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxUNorwGD42Y64wzgalSpEC5EuvLnSA3xtibdkIbR7BE5hT3h6rOn8D4ZyMEsal3iaAyaKkpNVkXCbOg/640?wx_fmt=png)    </code></pre><p>其中 Gain（(T,X）) 是特征 X 的信息增益。Entropy(T) 是整个集合的信息熵，第二项 Entropy(T,X) 是特征 X 的信息熵。</p><p>采用信息熵进行节点选择时，通过对该节点各个属性信息增益进行排序，选择具有最高信息增益的属性作为划分节点，过滤掉其他属性。</p><p>决策树模型存在的一个问题是容易过拟合。因为在其决策树构建过程中试图通过生成长一棵完整的树来拟合训练集，因此却降低了测试集的准确性。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxU95ztWMrZJ4Pib02XznYG2C9cpwBYjty5cSLp7ZaVVibXOPveMIwCrDscsm070VpHqN8iaxrbsMibrlA/640?wx_fmt=png" alt=""></p><p>通过剪枝技术可以减少小决策树的过拟合问题。</p><p><strong>分类的集成算法</strong></p><hr><p>集成算法是一个模型组。从技术上说，集成算法是单独训练几个有监督模型，并将训练好的模型以不同的方式进行融合，从而达到最终的得预测结果。集成后的模型比其中任何一个单独的模型都有更高的预测能力。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxU95ztWMrZJ4Pib02XznYG2CpPguThhzugicQsGjILibBtytW7duL35EAVtrLKtkdkFspKibcdMsmvxaw/640?wx_fmt=png" alt=""></p><p>### </p><p>随机森林分类器</p><p>随机森林分类器是一种基于<strong>装袋（bagging）</strong>的集成算法，即<strong>自举助聚合法 (bootstrap aggregation)</strong>。集成算法结合了多个相同或不同类型的算法来对对象进行分类（例如，SVM 的集成，基于朴素贝叶斯的集成或基于决策树的集成）。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxXKEyiadtvyXhicxUJJj68hlgWAN5Z0ibYJ9ujOyTkoicJV1GaBqKnUGmMr3pXly4CsJaZbJGMS3h2kpA/640?wx_fmt=png" alt=""></p><p>集成的基本思想是算法的组合提升了最终的结果。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxU95ztWMrZJ4Pib02XznYG2Cm7r535jFHoZjIgxiaBHYekacxJrJY3wd1ylFRiaJjDXAYqfxjW4AG17A/640?wx_fmt=png" alt=""></p><p>深度太大的决策树容易受过拟合的影响。但是随机森林通过在随机子集上构建决策树防止过拟合，主要原因是它会对所有树的结果进行投票的结果是所有树的分类结果的投票，从而消除了单棵树的偏差。</p><p>随机森林在决策树生增长的同时为模型增加了额外的随机性。它在分割节点时，不是搜索全部样本最重要的特征，而是在随机特征子集中搜索最佳特征。这种方式使得决策树具有多样性，从而能够得到更好的模型。</p><p>### </p><p>梯度提升分类器</p><p>梯度提升分类器是一种提升集成算法。提升 (boosting) 算法是为了减少偏差而对弱分类器的而进行的一种集成方法。与装袋（bagging）方法构建预测结果池不同，提升算法是一种分类器的串行方法，它把每个输出作为下一个分类器的输入。通常，在装袋算法中，每棵树在原始数据集的子集上并行训练，并用所有树预测结果的均值作为模型最终的预测结果；梯度提升模型，采用串行方式而非并行模式获得预测结果。每棵决策树预测前一棵决策树的误差，因而使误差获得提升。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxXKEyiadtvyXhicxUJJj68hlgEG4IQPH3cDicETRWQh4Yx8XngqQgs6DvEXibRoV2HDfqibBPcrAGtibgKA/640?wx_fmt=png" alt=""></p><p>梯度提升树的工作流程</p><ul><li><p>使用浅层决策树初始化预测结果。</p></li><li><p>计算残差值（实际预测值）。</p></li><li><p>构建另一棵浅层决策树，将上一棵树的残差作为输入进行预测。</p></li><li><p>用新预测值和学习率的乘积作为最新预测结果，更新原有预测结果。</p></li><li><p>重复步骤 2-4，进行一定次数的迭代（迭代的次数即为构建的决策树的个数）。</p></li></ul><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxUNorwGD42Y64wzgalSpEC5hUWiatYUhA70CMy6kab7OJtmeg8BOZEvAvULoaibVib86w4FsXn47LxCQ/640?wx_fmt=png" alt=""></p><p>如果想了解更多关于梯度提升分类器的知识，可参考：</p><p><a href="https://medium.com/mlreview/gradient-boosting-from-scratch-1e317ae4587d%20/t%20_blank" target="_blank" rel="noopener">https://medium.com/mlreview/gradient-boosting-from-scratch-1e317ae4587d%20/t%20_blank</a></p><p>分类器的性能</p><hr><p>### </p><p>混淆矩阵</p><p>混淆矩阵是一张表，这张表通过对比已知分类结果的测试数据的预测值和真实值表来描述衡量分类器的性能。在二分类的情况下，混淆矩阵是展示预测值和真实值四种不同结果组合的表。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxXKEyiadtvyXhicxUJJj68hlga5Tdh4x7JqD3A2CVSUVBCW5pzWe6X3gKoORVzAbpfTLZZZyaKgsFLg/640?wx_fmt=png" alt=""></p><p>多分类问题的混淆矩阵可以帮助你确认错误模式。</p><p>对于二元分类器：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/wc7YNPm3YxUNorwGD42Y64wzgalSpEC5zbJzk1GpBNou0gnT9BOasm0nEPXfGh7HkPT3aJkSIuOZsVicyWfDUSw/640?wx_fmt=jpeg" alt=""></p><p>### </p><p>假正例 &amp; 假负例</p><p>假正例和假负例用来衡量模型预测的分类效果。假正例是指模型错误地将负例预测为正例。假负例是指模型错误地将正例预测为负例。主对角线的值越大（主对角线为真正例和真负例），模型就越好；副对角线给出模型的最差预测结果。</p><p><strong>假正例</strong></p><p>下面给出一个假正例的例子。比如：模型将一封邮件分类为垃圾邮件（正例），但这封邮件实际并不是垃圾邮件。这就像一个警示，错误如果能被修正就更好，但是与假负例相比，它并不是一个严重的问题。</p><p>作者注：个人观点，这个例子举的不太好，对垃圾邮件来说，相比于错误地将垃圾邮件分类为正常邮件（假负例），将正常邮件错误地分类为垃圾邮件（假正例）是更严重的问题。</p><p><strong>假正例（I 型错误）</strong>——原假设正确而拒绝原假设。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxXKEyiadtvyXhicxUJJj68hlgRKibHNynW1Ij5ZIH3YgOrf137JSSEPE0eqvo9eWJDicrhqXFibMSEUD3A/640?wx_fmt=png" alt=""></p><p><strong>假负例</strong></p><p>假负例的一个例子。例如，该模型预测一封邮件不是垃圾邮件（负例），但实际上这封邮件是垃圾邮件。这就像一个危险的信号，错误应该被及早纠正，因为它比假正例更严重。</p><p><strong>假负例（II 型错误）</strong>——原假设错误而接受原假设</p><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/wc7YNPm3YxUNorwGD42Y64wzgalSpEC5F3w5DxlEnvI0aubhQtaDPvYY70ldw14Muk1An6ibNricraCGPKuOjpoQ/640?wx_fmt=jpeg" alt=""></p><p>上图能够很容易地说明上述指标。左图男士的测试结果是假正例因为男性不能怀孕；右图女士是假负例因为很明显她怀孕了。</p><p>从混淆矩阵，我们能计算出准确率、精度、召回率和 F-1 值。</p><p><strong>准确率</strong></p><p>准确率是模型预测正确的部分。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxXKEyiadtvyXhicxUJJj68hlgRzugOskRRkM4riaSG3BGhnPdM4ziaaia04icpyxUzgY1erRLYDiabX2hcwA/640?wx_fmt=png" alt=""></p><p>准确率的公式为：</p><pre><code>   ![](https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxUNorwGD42Y64wzgalSpEC5YqlsYjqTz0SrugicJJzLicsJtEViccQfIUF6r51ricVR3OJ6GYk0sblJ2w/640?wx_fmt=png)      </code></pre><p>当数据集不平衡，也就是正样本和负样本的数量存在显著差异时，单独依靠准确率不能评价模型的性能。精度和召回率是衡量不平衡数据集的更好的指标。</p><p><strong>精度</strong></p><p>精度是指在所有预测为正例的分类中，预测正确的程度为正例的效果。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxU95ztWMrZJ4Pib02XznYG2CTmG9GwzM2QK1wbbvbdSxUs2pDGdomrhmXt6A7POPU81VXnsGichw21g/640?wx_fmt=png" alt=""></p><p>精度越高越好。</p><p><strong>召回率</strong></p><p>召回率是指在所有预测为正例（被正确预测为真的和没被正确预测但为真的）的分类样本中，召回率是指预测正确的程度。它，也被称为敏感度或真正率（TPR）。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxU95ztWMrZJ4Pib02XznYG2C9zH59A2cLtOK1ibicuO1yiaE51Fy2ojIGtAgic7Qz9bjZspvKJrmtTa2IQ/640?wx_fmt=png" alt=""></p><p>召回率越高越好。</p><p><strong>F-1 值</strong></p><p>通常实用的做法是将精度和召回率合成一个指标 F-1 值更好用，特别是当你需要一种简单的方法来衡量两个分类器性能时。F-1 值是精度和召回率的调和平均值。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxXKEyiadtvyXhicxUJJj68hlg3oA16O6SWrpaemQfDHdq6Vye6RtMjtO3HZMf9Pr3zxbrDvf3ZUULDw/640?wx_fmt=png" alt=""></p><p>普通的通常均值将所有的值平等对待，而调和平均值给予较低的值更高的权重，从而能够更多地惩罚极端值。所以，如果精度和召回率都很高，则分类器将得到很高的 F-1 值。</p><p>### </p><p>接受者操作曲线（ROC）和曲线下的面积（AUC）</p><p>ROC 曲线是衡量分类器性能的一个很重要指标，它代表模型准确预测的程度。ROC 曲线通过绘制真正率和假正率的关系来衡量分类器的敏感度。如果分类器性能优越，则真正率将增加，曲线下的面积会接近于 1. 如果分类器类似于随机猜测，真正率将随假正率线性增加。AUC 值越大，模型效果越好。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxU95ztWMrZJ4Pib02XznYG2CMNoJNM0rYGbiaOrMzQZd0U6yZ2RLdV2PialwU9gsc2Wn9N6koUBo4awg/640?wx_fmt=png" alt=""></p><p>### </p><p>累积精度曲线</p><p>CAP 代表一个模型沿 y 轴为真正率的累积百分比与沿 x 轴的该分类样本累积百分比。CAP 不同于接受者操作曲线（ROC，绘制的是真正率与假正率的关系）。与 ROC 曲线相比，CAP 曲线很少使用。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxUNorwGD42Y64wzgalSpEC5e5M46NjLw1RBOQg0nkDxt6dD3vzxUBOZ5EV4vXNYjXdYVSMlGb6U7A/640?wx_fmt=png" alt=""> </p><p>以考虑一个预测客户是否会购买产品的模型为例，如果随机选择客户，他有 50% 的概率会购买产品。客户购买产品的累积数量会线性地增长到对应客户总量的最大值，这个曲线称为 CAP 随机曲线，为上图中的蓝色线。而一个完美的预测，准确地确定预测了哪些客户会购买产品，这样，在所有样本中只需选择最少的客户就能达到最大购买量。这在 CAP 曲线上产生了一条开始陡峭一旦达到最大值就会维持在 1 的折线，称为 CAP 的完美曲线，也被称为理想曲线，为上图中灰色的线。</p><p>最后，一个真实的模型应该能尽可能最大化地正确预测，接近于理想模型曲线。</p><p>参考链接：</p><p><a href="http://www.semspirit.com/artificial-intelligence/machine-learning/classification/classifier-evaluation/classifier-evaluation-with-cap-curve-in-python/&quot;&quot;_blank&quot;" target="_blank" rel="noopener">http://www.semspirit.com/artificial-intelligence/machine-learning/classification/classifier-evaluation/classifier-evaluation-with-cap-curve-in-python/""_blank"</a></p><p>分类器的代码见：</p><p><a href="https://github.com/BadreeshShetty/Supervised-ML-Classification&quot;&quot;_blank&quot;Github" target="_blank" rel="noopener">https://github.com/BadreeshShetty/Supervised-ML-Classification""_blank"Github</a> Repo</p><p>相关报道：</p><p><a href="https://builtin.com/data-science/supervised-machine-learning-classification" target="_blank" rel="noopener">https://builtin.com/data-science/supervised-machine-learning-classification</a></p><p>（完）</p><p>看完本文有收获？请转发分享给更多人</p><p><strong>关注「P**</strong>ython 那些事」，做全栈开发工程师**</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/MQ4FoG1HmnJxVd8o6xh6HKRZCSlKw94JvO1iaZ9roHrG47uPnib9KEheJ68bp9MZq4gQbQkxOhUWUicBMTSvNWiagw/640?wx_fmt=png" alt=""></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/wc7YNPm3YxU23ibAGj19P5mvODkkEB3o4wyW1PuIibq8icSVmQamWibsHpKgBxyhHSEdOHKhk1WpjbJY0xrqapicib0A/640?wx_fmt=png" alt=""></p><p>点「在看」的人都变好看了哦</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>matplotlib绘图</title>
      <link href="/2019/08/23/matplotlib-hui-tu/"/>
      <url>/2019/08/23/matplotlib-hui-tu/</url>
      
        <content type="html"><![CDATA[<pre><code>#-*- coding: utf-8 -*-#---------------------------------------------------#演示MatPlotLib中设置坐标轴主刻度标签和次刻度标签.#对于次刻度显示,如果要使用默认设置只要matplotlib.pyplot.minorticks_on()#---------------------------------------------------from pylab import *from matplotlib.ticker import  MultipleLocatorfrom matplotlib.ticker import  FormatStrFormatter#---------------------------------------------------#将x主刻度标签设置为20的倍数(也即以 20为主刻度单位其余可类推)xmajorLocator = MultipleLocator(20);#设置x轴标签文本的格式xmajorFormatter = FormatStrFormatter('%3.1f') #将x轴次刻度标签设置为5的倍数xminorLocator = MultipleLocator(5) #设定y 轴的主刻度间隔及相应的刻度间隔显示格式#将y轴主刻度标签设置为1.0的倍数ymajorLocator = MultipleLocator(1.0) #设置y轴标签文本的格式ymajorFormatter = FormatStrFormatter('%1.1f')#将此y轴次刻度标签设置为0.2的倍数yminorLocator = MultipleLocator(0.2) t = arange(1.0, 100.0, 1)s=t*exp(-t*1.3)+2*sqrt(t)#注意:一般都在ax中设置,不再plot中设置ax = subplot(111)plot(t,s,'--r*') #设置主刻度标签的位置,标签文本的格式ax.xaxis.set_major_locator(xmajorLocator)ax.xaxis.set_major_formatter(xmajorFormatter)ax.yaxis.set_major_locator(ymajorLocator)ax.yaxis.set_major_formatter(ymajorFormatter)#显示次刻度标签的位置,没有标签文本ax.xaxis.set_minor_locator(xminorLocator)ax.yaxis.set_minor_locator(yminorLocator)ax.xaxis.grid(True, which='major') #x坐标轴的网格使用主刻度ax.yaxis.grid(True, which='minor') #y坐标轴的网格使用次刻度show()</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python绘图 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Matplotlib </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ts</title>
      <link href="/2019/08/21/ts/"/>
      <url>/2019/08/21/ts/</url>
      
        <content type="html"><![CDATA[<h1 id="About-Keras-models"><a href="#About-Keras-models" class="headerlink" title="About Keras models"></a>About Keras models</h1><p>There are two types of models available in Keras: <a href="/models/sequential">the Sequential model</a> and <a href="/models/model">the Model class used with functional API</a>.</p><p>These models have a number of methods in common:</p><ul><li><p><code>model.summary()</code>: prints a summary representation of your model. Shortcut for <a href="/utils/#print_summary">utils.print_summary</a></p></li><li><p><code>model.get_config()</code>: returns a dictionary containing the configuration of the model. The model can be reinstantiated from its config via:</p><pre class=" language-python"><code class="language-python">config <span class="token operator">=</span> model<span class="token punctuation">.</span>get_config<span class="token punctuation">(</span><span class="token punctuation">)</span>model <span class="token operator">=</span> Model<span class="token punctuation">.</span>from_config<span class="token punctuation">(</span>config<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># or, for Sequential:</span>model <span class="token operator">=</span> Sequential<span class="token punctuation">.</span>from_config<span class="token punctuation">(</span>config<span class="token punctuation">)</span></code></pre></li><li><p><code>model.get_weights()</code>: returns a list of all weight tensors in the model, as Numpy arrays.</p></li><li><p><code>model.set_weights(weights)</code>: sets the values of the weights of the model, from a list of Numpy arrays. The arrays in the list should have the same shape as those returned by <code>get_weights()</code>.</p></li><li><p><code>model.to_json()</code>: returns a representation of the model as a JSON string. Note that the representation does not include the weights, only the architecture. You can reinstantiate the same model (with reinitialized weights) from the JSON string via:</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> model_from_json</code></pre></li></ul><p>json_string = model.to_json()<br>model = model_from_json(json_string)</p><pre><code>- `model.to_yaml()`: returns a representation of the model as a YAML string. Note that the representation does not include the weights, only the architecture. You can reinstantiate the same model (with reinitialized weights) from the YAML string via:```pythonfrom keras.models import model_from_yamlyaml_string = model.to_yaml()model = model_from_yaml(yaml_string)</code></pre><ul><li><code>model.save_weights(filepath)</code>: saves the weights of the model as a HDF5 file.</li><li><code>model.load_weights(filepath, by_name=False)</code>: loads the weights of the model from a HDF5 file (created by <code>save_weights</code>). By default, the architecture is expected to be unchanged. To load weights into a different architecture (with some layers in common), use <code>by_name=True</code> to load only those layers with the same name.</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Keras </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python 基础学习记录</title>
      <link href="/2019/08/21/test3/"/>
      <url>/2019/08/21/test3/</url>
      
        <content type="html"><![CDATA[<h1 id="Python-Traffic-Counter"><a href="#Python-Traffic-Counter" class="headerlink" title="Python Traffic Counter"></a>Python Traffic Counter</h1><p>The purpose of this project is to detect and track vehicles on a video stream and count those going through a defined line. </p><p><img src="/.io//highway.gif" alt="highway.gif"></p><p>It uses:</p><ul><li><p><a href="https://www.pyimagesearch.com/2018/11/12/yolo-object-detection-with-opencv" target="_blank" rel="noopener">YOLO</a> to detect objects on each of the video frames.</p></li><li><p><a href="https://github.com/abewley/sort" target="_blank" rel="noopener">SORT</a> to track those objects over different frames.</p></li></ul><p>Once the objects are detected and tracked over different frames a simple mathematical calculation is applied to count the intersections between the vehicles previous and current frame positions with a defined line.</p><p>The code on this prototype uses the code structure developed by Adrian Rosebrock for his article <a href="https://www.pyimagesearch.com/2018/11/12/yolo-object-detection-with-opencv" target="_blank" rel="noopener">YOLO object detection with OpenCV</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><ol><li>Download the code to your computer.</li><li><a href="https://www.dropbox.com/s/99mm7olr1ohtjbq/yolov3.weights?dl=0" target="_blank" rel="noopener">Download yolov3.weights</a> and place it in <code>/yolo-coco</code>.</li><li>Make sure you have Python 3.7.0 and <a href="https://www.pyimagesearch.com/opencv-tutorials-resources-guides/" target="_blank" rel="noopener">OpenCV 3.4.2</a> installed.</li><li>Run:<pre><code>$ python main.py --input input/highway.mp4 --output output/highway.avi --yolo yolo-coco</code></pre></li></ol><h2 id="Citation"><a href="#Citation" class="headerlink" title="Citation"></a>Citation</h2><h3 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO :"></a>YOLO :</h3><pre><code>@article{redmon2016yolo9000,  title={YOLO9000: Better, Faster, Stronger},  author={Redmon, Joseph and Farhadi, Ali},  journal={arXiv preprint arXiv:1612.08242},  year={2016}}</code></pre><h3 id="SORT"><a href="#SORT" class="headerlink" title="SORT :"></a>SORT :</h3><pre><code>@inproceedings{Bewley2016_sort,  author={Bewley, Alex and Ge, Zongyuan and Ott, Lionel and Ramos, Fabio and Upcroft, Ben},  booktitle={2016 IEEE International Conference on Image Processing (ICIP)},  title={Simple online and realtime tracking},  year={2016},  pages={3464-3468},  keywords={Benchmark testing;Complexity theory;Detectors;Kalman filters;Target tracking;Visualization;Computer Vision;Data Association;Detection;Multiple Object Tracking},  doi={10.1109/ICIP.2016.7533003}}</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Markdown </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>About Keras models</title>
      <link href="/2019/08/21/test2/"/>
      <url>/2019/08/21/test2/</url>
      
        <content type="html"><![CDATA[<h1 id="About-Keras-models"><a href="#About-Keras-models" class="headerlink" title="About Keras models"></a>About Keras models</h1><p>There are two types of models available in Keras: <a href="/models/sequential">the Sequential model</a> and <a href="/models/model">the Model class used with functional API</a>.</p><p>These models have a number of methods in common:</p><ul><li><p><code>model.summary()</code>: prints a summary representation of your model. Shortcut for <a href="/utils/#print_summary">utils.print_summary</a></p></li><li><p><code>model.get_config()</code>: returns a dictionary containing the configuration of the model. The model can be reinstantiated from its config via:</p><pre class=" language-python"><code class="language-python">config <span class="token operator">=</span> model<span class="token punctuation">.</span>get_config<span class="token punctuation">(</span><span class="token punctuation">)</span>model <span class="token operator">=</span> Model<span class="token punctuation">.</span>from_config<span class="token punctuation">(</span>config<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># or, for Sequential:</span>model <span class="token operator">=</span> Sequential<span class="token punctuation">.</span>from_config<span class="token punctuation">(</span>config<span class="token punctuation">)</span></code></pre></li><li><p><code>model.get_weights()</code>: returns a list of all weight tensors in the model, as Numpy arrays.</p></li><li><p><code>model.set_weights(weights)</code>: sets the values of the weights of the model, from a list of Numpy arrays. The arrays in the list should have the same shape as those returned by <code>get_weights()</code>.</p></li><li><p><code>model.to_json()</code>: returns a representation of the model as a JSON string. Note that the representation does not include the weights, only the architecture. You can reinstantiate the same model (with reinitialized weights) from the JSON string via:</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> model_from_json</code></pre></li></ul><p>json_string = model.to_json()<br>model = model_from_json(json_string)</p><pre><code>- `model.to_yaml()`: returns a representation of the model as a YAML string. Note that the representation does not include the weights, only the architecture. You can reinstantiate the same model (with reinitialized weights) from the YAML string via:```pythonfrom keras.models import model_from_yamlyaml_string = model.to_yaml()model = model_from_yaml(yaml_string)</code></pre><ul><li><code>model.save_weights(filepath)</code>: saves the weights of the model as a HDF5 file.</li><li><code>model.load_weights(filepath, by_name=False)</code>: loads the weights of the model from a HDF5 file (created by <code>save_weights</code>). By default, the architecture is expected to be unchanged. To load weights into a different architecture (with some layers in common), use <code>by_name=True</code> to load only those layers with the same name.</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Keras </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>XGBOOST introduction</title>
      <link href="/2019/08/21/test/"/>
      <url>/2019/08/21/test/</url>
      
        <content type="html"><![CDATA[<h1 id="Awesome-XGBoost"><a href="#Awesome-XGBoost" class="headerlink" title="Awesome XGBoost"></a>Awesome XGBoost</h1><p>This page contains a curated list of examples, tutorials, blogs about XGBoost usecases.<br>It is inspired by <a href="https://github.com/dmlc/mxnet/blob/master/example/README.md" target="_blank" rel="noopener">awesome-MXNet</a>,<br><a href="https://github.com/ziadoz/awesome-php" target="_blank" rel="noopener">awesome-php</a> and <a href="https://github.com/josephmisiti/awesome-machine-learning" target="_blank" rel="noopener">awesome-machine-learning</a>.</p><p>Please send a pull request if you find things that belongs to here.</p><h2 id="Contents"><a href="#Contents" class="headerlink" title="Contents"></a>Contents</h2><ul><li><a href="#code-examples">Code Examples</a><ul><li><a href="#features-walkthrough">Features Walkthrough</a></li><li><a href="#basic-examples-by-tasks">Basic Examples by Tasks</a></li><li><a href="#benchmarks">Benchmarks</a></li></ul></li><li><a href="#machine-learning-challenge-winning-solutions">Machine Learning Challenge Winning Solutions</a></li><li><a href="#tutorials">Tutorials</a></li><li><a href="#usecases">Usecases</a></li><li><a href="#tools-using-xgboost">Tools using XGBoost</a></li><li><a href="#awards">Awards</a></li><li><a href="#windows-binaries">Windows Binaries</a></li></ul><h2 id="Code-Examples"><a href="#Code-Examples" class="headerlink" title="Code Examples"></a>Code Examples</h2><h3 id="Features-Walkthrough"><a href="#Features-Walkthrough" class="headerlink" title="Features Walkthrough"></a>Features Walkthrough</h3><p>This is a list of short codes introducing different functionalities of xgboost packages.</p><ul><li>Basic walkthrough of packages<br><a href="guide-python/basic_walkthrough.py">python</a><br><a href="../R-package/demo/basic_walkthrough.R">R</a><br><a href="https://github.com/antinucleon/XGBoost.jl/blob/master/demo/basic_walkthrough.jl" target="_blank" rel="noopener">Julia</a><br><a href="https://github.com/bpachev/xgboost-php/blob/master/demo/titanic_demo.php" target="_blank" rel="noopener">PHP</a></li><li>Customize loss function, and evaluation metric<br><a href="guide-python/custom_objective.py">python</a><br><a href="../R-package/demo/custom_objective.R">R</a><br><a href="https://github.com/antinucleon/XGBoost.jl/blob/master/demo/custom_objective.jl" target="_blank" rel="noopener">Julia</a></li><li>Boosting from existing prediction<br><a href="guide-python/boost_from_prediction.py">python</a><br><a href="../R-package/demo/boost_from_prediction.R">R</a><br><a href="https://github.com/antinucleon/XGBoost.jl/blob/master/demo/boost_from_prediction.jl" target="_blank" rel="noopener">Julia</a></li><li>Predicting using first n trees<br><a href="guide-python/predict_first_ntree.py">python</a><br><a href="../R-package/demo/predict_first_ntree.R">R</a><br><a href="https://github.com/antinucleon/XGBoost.jl/blob/master/demo/predict_first_ntree.jl" target="_blank" rel="noopener">Julia</a></li><li>Generalized Linear Model<br><a href="guide-python/generalized_linear_model.py">python</a><br><a href="../R-package/demo/generalized_linear_model.R">R</a><br><a href="https://github.com/antinucleon/XGBoost.jl/blob/master/demo/generalized_linear_model.jl" target="_blank" rel="noopener">Julia</a></li><li>Cross validation<br><a href="guide-python/cross_validation.py">python</a><br><a href="../R-package/demo/cross_validation.R">R</a><br><a href="https://github.com/antinucleon/XGBoost.jl/blob/master/demo/cross_validation.jl" target="_blank" rel="noopener">Julia</a></li><li>Predicting leaf indices<br><a href="guide-python/predict_leaf_indices.py">python</a><br><a href="../R-package/demo/predict_leaf_indices.R">R</a></li></ul><h3 id="Basic-Examples-by-Tasks"><a href="#Basic-Examples-by-Tasks" class="headerlink" title="Basic Examples by Tasks"></a>Basic Examples by Tasks</h3><p>Most of examples in this section are based on CLI or python version.<br>However, the parameter settings can be applied to all versions</p><ul><li><a href="binary_classification">Binary classification</a></li><li><a href="multiclass_classification">Multiclass classification</a></li><li><a href="regression">Regression</a></li><li><a href="rank">Learning to Rank</a></li></ul><h3 id="Benchmarks"><a href="#Benchmarks" class="headerlink" title="Benchmarks"></a>Benchmarks</h3><ul><li><a href="kaggle-higgs">Starter script for Kaggle Higgs Boson</a></li><li><a href="https://github.com/daxiongshu/kaggle-tradeshift-winning-solution" target="_blank" rel="noopener">Kaggle Tradeshift winning solution by daxiongshu</a></li><li><a href="https://github.com/szilard/benchm-ml#boosting-gradient-boosted-treesgradient-boosting-machines" target="_blank" rel="noopener">Benchmarking the most commonly used open source tools for binary classification</a></li></ul><h2 id="Machine-Learning-Challenge-Winning-Solutions"><a href="#Machine-Learning-Challenge-Winning-Solutions" class="headerlink" title="Machine Learning Challenge Winning Solutions"></a>Machine Learning Challenge Winning Solutions</h2><p>XGBoost is extensively used by machine learning practitioners to create state of art data science solutions,<br>this is a list of machine learning winning solutions with XGBoost.<br>Please send pull requests if you find ones that are missing here.</p><ul><li>Maksims Volkovs, Guangwei Yu and Tomi Poutanen, 1st place of the <a href="http://2017.recsyschallenge.com/" target="_blank" rel="noopener">2017 ACM RecSys challenge</a>. Link to <a href="http://www.cs.toronto.edu/~mvolkovs/recsys2017_challenge.pdf" target="_blank" rel="noopener">paper</a>.</li><li>Vlad Sandulescu, Mihai Chiru, 1st place of the <a href="https://kddcup2016.azurewebsites.net" target="_blank" rel="noopener">KDD Cup 2016 competition</a>. Link to <a href="http://arxiv.org/abs/1609.02728" target="_blank" rel="noopener">the arxiv paper</a>.</li><li>Marios Michailidis, Mathias Müller and HJ van Veen, 1st place of the <a href="https://www.kaggle.com/c/dato-native" target="_blank" rel="noopener">Dato Truely Native? competition</a>. Link to <a href="http://blog.kaggle.com/2015/12/03/dato-winners-interview-1st-place-mad-professors/" target="_blank" rel="noopener">the Kaggle interview</a>.</li><li>Vlad Mironov, Alexander Guschin, 1st place of the <a href="https://www.kaggle.com/c/flavours-of-physics" target="_blank" rel="noopener">CERN LHCb experiment Flavour of Physics competition</a>. Link to <a href="http://blog.kaggle.com/2015/11/30/flavour-of-physics-technical-write-up-1st-place-go-polar-bears/" target="_blank" rel="noopener">the Kaggle interview</a>.</li><li>Josef Slavicek, 3rd place of the <a href="https://www.kaggle.com/c/flavours-of-physics" target="_blank" rel="noopener">CERN LHCb experiment Flavour of Physics competition</a>. Link to <a href="http://blog.kaggle.com/2015/11/23/flavour-of-physics-winners-interview-3rd-place-josef-slavicek/" target="_blank" rel="noopener">the Kaggle interview</a>.</li><li>Mario Filho, Josef Feigl, Lucas, Gilberto, 1st place of the <a href="https://www.kaggle.com/c/caterpillar-tube-pricing" target="_blank" rel="noopener">Caterpillar Tube Pricing competition</a>. Link to <a href="http://blog.kaggle.com/2015/09/22/caterpillar-winners-interview-1st-place-gilberto-josef-leustagos-mario/" target="_blank" rel="noopener">the Kaggle interview</a>.</li><li>Qingchen Wang, 1st place of the <a href="https://www.kaggle.com/c/liberty-mutual-group-property-inspection-prediction" target="_blank" rel="noopener">Liberty Mutual Property Inspection</a>. Link to <a href="http://blog.kaggle.com/2015/09/28/liberty-mutual-property-inspection-winners-interview-qingchen-wang/" target="_blank" rel="noopener">the Kaggle interview</a>.</li><li>Chenglong Chen, 1st place of the <a href="https://www.kaggle.com/c/crowdflower-search-relevance" target="_blank" rel="noopener">Crowdflower Search Results Relevance</a>. Link to <a href="https://www.kaggle.com/c/crowdflower-search-relevance/forums/t/15186/1st-place-winner-solution-chenglong-chen/" target="_blank" rel="noopener">the winning solution</a>.</li><li>Alexandre Barachant (“Cat”) and Rafał Cycoń (“Dog”), 1st place of the <a href="https://www.kaggle.com/c/grasp-and-lift-eeg-detection" target="_blank" rel="noopener">Grasp-and-Lift EEG Detection</a>. Link to <a href="http://blog.kaggle.com/2015/10/12/grasp-and-lift-eeg-winners-interview-1st-place-cat-dog/" target="_blank" rel="noopener">the Kaggle interview</a>.</li><li>Halla Yang, 2nd place of the <a href="https://www.kaggle.com/c/coupon-purchase-prediction" target="_blank" rel="noopener">Recruit Coupon Purchase Prediction Challenge</a>. Link to <a href="http://blog.kaggle.com/2015/10/21/recruit-coupon-purchase-winners-interview-2nd-place-halla-yang/" target="_blank" rel="noopener">the Kaggle interview</a>.</li><li>Owen Zhang, 1st place of the <a href="https://www.kaggle.com/c/avito-context-ad-clicks" target="_blank" rel="noopener">Avito Context Ad Clicks competition</a>. Link to <a href="http://blog.kaggle.com/2015/08/26/avito-winners-interview-1st-place-owen-zhang/" target="_blank" rel="noopener">the Kaggle interview</a>.</li><li>Keiichi Kuroyanagi, 2nd place of the <a href="https://www.kaggle.com/c/airbnb-recruiting-new-user-bookings" target="_blank" rel="noopener">Airbnb New User Bookings</a>. Link to <a href="http://blog.kaggle.com/2016/03/17/airbnb-new-user-bookings-winners-interview-2nd-place-keiichi-kuroyanagi-keiku/" target="_blank" rel="noopener">the Kaggle interview</a>.</li><li>Marios Michailidis, Mathias Müller and Ning Situ, 1st place <a href="https://www.kaggle.com/c/homesite-quote-conversion" target="_blank" rel="noopener">Homesite Quote Conversion</a>. Link to <a href="http://blog.kaggle.com/2016/04/08/homesite-quote-conversion-winners-write-up-1st-place-kazanova-faron-clobber/" target="_blank" rel="noopener">the Kaggle interview</a>.</li></ul><h2 id="Talks"><a href="#Talks" class="headerlink" title="Talks"></a>Talks</h2><ul><li><a href="http://datascience.la/xgboost-workshop-and-meetup-talk-with-tianqi-chen/" target="_blank" rel="noopener">XGBoost: A Scalable Tree Boosting System</a> (video+slides) by Tianqi Chen at the Los Angeles Data Science meetup</li></ul><h2 id="Tutorials"><a href="#Tutorials" class="headerlink" title="Tutorials"></a>Tutorials</h2><ul><li><a href="https://www.qubole.com/blog/machine-learning-xgboost-qubole-spark-cluster/" target="_blank" rel="noopener">Machine Learning with XGBoost on Qubole Spark Cluster</a></li><li><a href="https://xgboost.readthedocs.org/en/latest/R-package/index.html#tutorials" target="_blank" rel="noopener">XGBoost Official RMarkdown Tutorials</a></li><li><a href="http://dmlc.ml/rstats/2016/03/10/xgboost.html" target="_blank" rel="noopener">An Introduction to XGBoost R Package</a> by Tong He</li><li><a href="http://www.slideshare.net/odsc/owen-zhangopen-sourcetoolsanddscompetitions1" target="_blank" rel="noopener">Open Source Tools &amp; Data Science Competitions</a> by Owen Zhang - XGBoost parameter tuning tips</li></ul><ul><li><a href="http://fr.slideshare.net/MichaelBENESTY/feature-importance-analysis-with-xgboost-in-tax-audit" target="_blank" rel="noopener">Feature Importance Analysis with XGBoost in Tax audit</a></li><li><a href="http://no2147483647.wordpress.com/2014/09/17/winning-solution-of-kaggle-higgs-competition-what-a-single-model-can-do/" target="_blank" rel="noopener">Winning solution of Kaggle Higgs competition: what a single model can do</a></li></ul><ul><li><p><a href="http://www.slideshare.net/ShangxuanZhang/xgboost" target="_blank" rel="noopener">XGBoost - eXtreme Gradient Boosting</a> by Tong He</p></li><li><p><a href="http://www.analyticsvidhya.com/blog/2016/01/xgboost-algorithm-easy-steps/" target="_blank" rel="noopener">How to use XGBoost algorithm in R in easy steps</a> by TAVISH SRIVASTAVA (<a href="https://segmentfault.com/a/1190000004421821" target="_blank" rel="noopener">Chinese Translation 中文翻译</a> by <a href="https://segmentfault.com/u/harryprince" target="_blank" rel="noopener">HarryZhu</a>)</p></li><li><p><a href="http://www.analyticsvidhya.com/blog/2015/12/kaggle-solution-cooking-text-mining-competition/" target="_blank" rel="noopener">Kaggle Solution: What’s Cooking ? (Text Mining Competition)</a> by MANISH SARASWAT</p></li><li><p>Better Optimization with Repeated Cross Validation and the XGBoost model - Machine Learning with R) by Manuel Amunategui (<a href="https://www.youtube.com/watch?v=Og7CGAfSr_Y" target="_blank" rel="noopener">Youtube Link</a> (<a href="https://github.com/amunategui/BetterCrossValidation" target="_blank" rel="noopener">Github Link</a>)</p></li><li><p><a href="https://www.kaggle.com/khozzy/rossmann-store-sales/xgboost-parameter-tuning-template/run/90168/notebook" target="_blank" rel="noopener">XGBoost Rossman Parameter Tuning</a> by <a href="https://www.kaggle.com/khozzy" target="_blank" rel="noopener">Norbert Kozlowski</a></p></li><li><p><a href="http://www.slideshare.net/DataRobot/featurizing-log-data-before-xgboost" target="_blank" rel="noopener">Featurizing log data before XGBoost</a> by Xavier Conort, Owen Zhang etc</p></li><li><p><a href="http://blog.kaggle.com/2015/07/21/west-nile-virus-competition-benchmarks-tutorials/" target="_blank" rel="noopener">West Nile Virus Competition Benchmarks &amp; Tutorials</a> by <a href="http://blog.kaggle.com/author/annamontoya/" target="_blank" rel="noopener">Anna Montoya</a></p></li><li><p><a href="https://www.kaggle.com/binghsu/predict-west-nile-virus/xgboost-starter-code-python-0-69" target="_blank" rel="noopener">Ensemble Decision Tree with XGBoost</a> by <a href="https://www.kaggle.com/binghsu" target="_blank" rel="noopener">Bing Xu</a></p></li><li><p><a href="http://startup.ml/blog/xgboost" target="_blank" rel="noopener">Notes on eXtreme Gradient Boosting</a> by ARSHAK NAVRUZYAN (<a href="https://github.com/startupml/koan/blob/master/eXtreme%20Gradient%20Boosting.ipynb" target="_blank" rel="noopener">iPython Notebook</a>)</p></li><li><p><a href="http://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/" target="_blank" rel="noopener">Complete Guide to Parameter Tuning in XGBoost</a> by Aarshay Jain</p></li><li><p><a href="http://education.parrotprediction.teachable.com/courses/practical-xgboost-in-python" target="_blank" rel="noopener">Practical XGBoost in Python online course</a> by Parrot Prediction</p></li><li><p><a href="http://www.elenacuoco.com/2016/10/10/scala-spark-xgboost-classification/" target="_blank" rel="noopener">Spark and XGBoost using Scala</a> by Elena Cuoco</p><h2 id="Usecases"><a href="#Usecases" class="headerlink" title="Usecases"></a>Usecases</h2><p>If you have particular usecase of xgboost that you would like to highlight.<br>Send a PR to add a one sentence description:)</p></li><li><p>XGBoost is used in <a href="https://www.kaggle.com/scripts" target="_blank" rel="noopener">Kaggle Script</a> to solve data science challenges.</p></li><li><p><a href="http://docs.seldon.io/iris-demo.html" target="_blank" rel="noopener">Seldon predictive service powered by XGBoost</a></p></li><li><p>XGBoost Distributed is used in <a href="https://yq.aliyun.com/articles/6355" target="_blank" rel="noopener">ODPS Cloud Service by Alibaba</a> (in Chinese)</p></li><li><p>XGBoost is incoporated as part of <a href="https://dato.com/products/create/" target="_blank" rel="noopener">Graphlab Create</a> for scalable machine learning.</p></li><li><p><a href="https://www.52cs.org" target="_blank" rel="noopener">Hanjing Su</a> from Tencent data platform team: “We use distributed XGBoost for click through prediction in wechat shopping and lookalikes. The problems involve hundreds millions of users and thousands of features. XGBoost is cleanly designed and can be easily integrated into our production environment, reducing our cost in developments.”</p></li><li><p><a href="https://github.com/CNevd" target="_blank" rel="noopener">CNevd</a> from autohome.com ad platform team: “Distributed XGBoost is used for click through rate prediction in our display advertising, XGBoost is highly efficient and flexible and can be easily used on our distributed platform, our ctr made a great improvement with hundred millions samples and millions features due to this awesome XGBoost”</p></li></ul><h2 id="Tools-using-XGBoost"><a href="#Tools-using-XGBoost" class="headerlink" title="Tools using XGBoost"></a>Tools using XGBoost</h2><ul><li><a href="https://github.com/mpearmain/BayesBoost" target="_blank" rel="noopener">BayesBoost</a> - Bayesian Optimization using xgboost and sklearn API</li><li><a href="https://github.com/vatsan/gp_xgboost_gridsearch" target="_blank" rel="noopener">gp_xgboost_gridsearch</a> - In-database parallel grid-search for XGBoost on <a href="https://github.com/greenplum-db/gpdb" target="_blank" rel="noopener">Greenplum</a> using PL/Python</li><li><a href="https://github.com/rhiever/tpot" target="_blank" rel="noopener">tpot</a> - A Python tool that automatically creates and optimizes machine learning pipelines using genetic programming.</li></ul><h2 id="Awards"><a href="#Awards" class="headerlink" title="Awards"></a>Awards</h2><ul><li><a href="http://stat-computing.org/awards/jmc/winners.html" target="_blank" rel="noopener">John Chambers Award</a> - 2016 Winner: XGBoost R Package, by Tong He (Simon Fraser University) and Tianqi Chen (University of Washington)</li></ul><h2 id="Windows-Binaries"><a href="#Windows-Binaries" class="headerlink" title="Windows Binaries"></a>Windows Binaries</h2><p>Unofficial windows binaries and instructions on how to use them are hosted on <a href="http://www.picnet.com.au/blogs/guido/post/2016/09/22/xgboost-windows-x64-binaries-for-download/" target="_blank" rel="noopener">Guido Tapia’s blog</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> XGBoost </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
